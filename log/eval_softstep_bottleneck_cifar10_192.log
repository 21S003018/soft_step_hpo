softstep_bottleneck_cifar10/192_o1_cifar-10-batches-py
Files already downloaded and verified
Files already downloaded and verified
Epoch~1->train_loss:1.6396, val_loss:1.3643, val_accu:0.5363, time:72.553
Epoch~2->train_loss:1.0244, val_loss:0.8319, val_accu:0.7136, time:67.3169
Epoch~3->train_loss:0.7654, val_loss:0.6928, val_accu:0.7617, time:67.2388
Epoch~4->train_loss:0.6144, val_loss:0.6668, val_accu:0.7804, time:67.1691
Epoch~5->train_loss:0.5227, val_loss:0.5714, val_accu:0.8112, time:67.2075
Epoch~6->train_loss:0.4648, val_loss:0.5103, val_accu:0.8236, time:67.3415
Epoch~7->time:67.228
Epoch~8->train_loss:0.3853, val_loss:0.4084, val_accu:0.8608, time:67.2541
Epoch~9->time:67.3541
Epoch~10->train_loss:0.328, val_loss:0.4166, val_accu:0.8643, time:66.9473
Epoch~11->time:67.1168
Epoch~12->train_loss:0.2871, val_loss:0.3927, val_accu:0.868, time:67.2069
Epoch~13->train_loss:0.2736, val_loss:0.3816, val_accu:0.8718, time:67.3256
Epoch~14->train_loss:0.2584, val_loss:0.3684, val_accu:0.8771, time:67.3097
Epoch~15->time:66.9376
Epoch~16->time:67.2379
Epoch~17->train_loss:0.2262, val_loss:0.3515, val_accu:0.885, time:67.1488
Epoch~18->time:67.087
Epoch~19->train_loss:0.2093, val_loss:0.3285, val_accu:0.8894, time:67.0086
Epoch~20->time:67.1747
Epoch~21->time:67.2393
Epoch~22->time:67.2827
Epoch~23->train_loss:0.1823, val_loss:0.3518, val_accu:0.8895, time:67.0649
Epoch~24->time:67.2794
Epoch~25->train_loss:0.177, val_loss:0.3348, val_accu:0.8926, time:67.2283
Epoch~26->train_loss:0.1637, val_loss:0.3306, val_accu:0.8968, time:67.0779
Epoch~27->time:67.3046
Epoch~28->time:67.0834
Epoch~29->time:67.2067
Epoch~30->time:67.0931
Epoch~31->time:67.5603
Epoch~32->time:67.6397
Epoch~33->time:67.8021
Epoch~34->time:67.7405
Epoch~35->time:67.6917
Epoch~36->train_loss:0.1327, val_loss:0.3334, val_accu:0.8982, time:67.7002
Epoch~37->train_loss:0.127, val_loss:0.3349, val_accu:0.8989, time:67.4096
Epoch~38->time:67.6082
Epoch~39->train_loss:0.1238, val_loss:0.3422, val_accu:0.9009, time:67.4519
Epoch~40->train_loss:0.1237, val_loss:0.3227, val_accu:0.9033, time:67.7241
Epoch~41->time:67.6396
Epoch~42->train_loss:0.121, val_loss:0.3117, val_accu:0.9067, time:67.9688
Epoch~43->time:68.2419
Epoch~44->time:68.0749
Epoch~45->time:67.7088
Epoch~46->time:67.843
Epoch~47->time:67.8311
Epoch~48->time:68.0005
Epoch~49->train_loss:0.1073, val_loss:0.3103, val_accu:0.9071, time:67.7934
Epoch~50->train_loss:0.1089, val_loss:0.3062, val_accu:0.9095, time:67.5724
Epoch~51->time:67.7494
Epoch~52->time:67.5361
Epoch~53->time:67.1499
Epoch~54->time:67.3076
Epoch~55->time:67.063
Epoch~56->time:67.0868
Epoch~57->time:67.0942
Epoch~58->time:67.3519
Epoch~59->time:67.0347
Epoch~60->time:67.1412
Epoch~61->time:67.2429
Epoch~62->time:67.3221
Epoch~63->time:67.1575
Epoch~64->train_loss:0.0878, val_loss:0.3189, val_accu:0.9096, time:67.3199
Epoch~65->train_loss:0.0835, val_loss:0.3172, val_accu:0.9117, time:67.1833
Epoch~66->time:67.2693
Epoch~67->time:67.2963
Epoch~68->time:67.1073
Epoch~69->time:66.9198
Epoch~70->time:67.2275
Epoch~71->time:67.2434
Epoch~72->time:67.0564
Epoch~73->train_loss:0.0798, val_loss:0.3026, val_accu:0.9151, time:67.2589
Epoch~74->train_loss:0.0794, val_loss:0.3002, val_accu:0.9171, time:67.1557
Epoch~75->time:66.9851
Epoch~76->time:67.241
Epoch~77->time:67.165
Epoch~78->time:67.2755
Epoch~79->time:67.1953
Epoch~80->time:67.3552
Epoch~81->train_loss:0.0647, val_loss:0.3043, val_accu:0.9217, time:66.9627
Epoch~82->time:67.4119
Epoch~83->time:67.1
Epoch~84->time:67.4071
Epoch~85->time:67.2884
Epoch~86->time:66.801
Epoch~87->time:66.7503
Epoch~88->time:67.0908
Epoch~89->time:67.1857
Epoch~90->time:67.1215
Epoch~91->time:67.1413
Epoch~92->time:67.3045
Epoch~93->time:67.1445
Epoch~94->time:67.1247
Epoch~95->time:67.1373
Epoch~96->train_loss:0.0458, val_loss:0.2857, val_accu:0.9237, time:67.4493
