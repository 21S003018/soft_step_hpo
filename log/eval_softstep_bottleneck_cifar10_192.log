softstep_bottleneck_cifar10/192_o1_cifar-10-batches-py
Files already downloaded and verified
Files already downloaded and verified
Epoch~1->train_loss:1.6396, val_loss:1.3643, val_accu:0.5363, time:72.553
Epoch~2->train_loss:1.0244, val_loss:0.8319, val_accu:0.7136, time:67.3169
Epoch~3->train_loss:0.7654, val_loss:0.6928, val_accu:0.7617, time:67.2388
Epoch~4->train_loss:0.6144, val_loss:0.6668, val_accu:0.7804, time:67.1691
Epoch~5->train_loss:0.5227, val_loss:0.5714, val_accu:0.8112, time:67.2075
Epoch~6->train_loss:0.4648, val_loss:0.5103, val_accu:0.8236, time:67.3415
Epoch~7->time:67.228
Epoch~8->train_loss:0.3853, val_loss:0.4084, val_accu:0.8608, time:67.2541
Epoch~9->time:67.3541
Epoch~10->train_loss:0.328, val_loss:0.4166, val_accu:0.8643, time:66.9473
Epoch~11->time:67.1168
Epoch~12->train_loss:0.2871, val_loss:0.3927, val_accu:0.868, time:67.2069
Epoch~13->train_loss:0.2736, val_loss:0.3816, val_accu:0.8718, time:67.3256
Epoch~14->train_loss:0.2584, val_loss:0.3684, val_accu:0.8771, time:67.3097
Epoch~15->time:66.9376
Epoch~16->time:67.2379
Epoch~17->train_loss:0.2262, val_loss:0.3515, val_accu:0.885, time:67.1488
Epoch~18->time:67.087
Epoch~19->train_loss:0.2093, val_loss:0.3285, val_accu:0.8894, time:67.0086
Epoch~20->time:67.1747
Epoch~21->time:67.2393
Epoch~22->time:67.2827
Epoch~23->train_loss:0.1823, val_loss:0.3518, val_accu:0.8895, time:67.0649
Epoch~24->time:67.2794
Epoch~25->train_loss:0.177, val_loss:0.3348, val_accu:0.8926, time:67.2283
Epoch~26->train_loss:0.1637, val_loss:0.3306, val_accu:0.8968, time:67.0779
Epoch~27->time:67.3046
Epoch~28->time:67.0834
Epoch~29->time:67.2067
Epoch~30->time:67.0931
Epoch~31->time:67.5603
Epoch~32->time:67.6397
Epoch~33->time:67.8021
Epoch~34->time:67.7405
Epoch~35->time:67.6917
Epoch~36->train_loss:0.1327, val_loss:0.3334, val_accu:0.8982, time:67.7002
Epoch~37->train_loss:0.127, val_loss:0.3349, val_accu:0.8989, time:67.4096
Epoch~38->time:67.6082
Epoch~39->train_loss:0.1238, val_loss:0.3422, val_accu:0.9009, time:67.4519
Epoch~40->train_loss:0.1237, val_loss:0.3227, val_accu:0.9033, time:67.7241
Epoch~41->time:67.6396
Epoch~42->train_loss:0.121, val_loss:0.3117, val_accu:0.9067, time:67.9688
Epoch~43->time:68.2419
Epoch~44->time:68.0749
Epoch~45->time:67.7088
Epoch~46->time:67.843
Epoch~47->time:67.8311
Epoch~48->time:68.0005
Epoch~49->train_loss:0.1073, val_loss:0.3103, val_accu:0.9071, time:67.7934
Epoch~50->train_loss:0.1089, val_loss:0.3062, val_accu:0.9095, time:67.5724
Epoch~51->time:67.7494
Epoch~52->time:67.5361
Epoch~53->time:67.1499
Epoch~54->time:67.3076
Epoch~55->time:67.063
Epoch~56->time:67.0868
Epoch~57->time:67.0942
Epoch~58->time:67.3519
Epoch~59->time:67.0347
Epoch~60->time:67.1412
Epoch~61->time:67.2429
Epoch~62->time:67.3221
Epoch~63->time:67.1575
Epoch~64->train_loss:0.0878, val_loss:0.3189, val_accu:0.9096, time:67.3199
Epoch~65->train_loss:0.0835, val_loss:0.3172, val_accu:0.9117, time:67.1833
Epoch~66->time:67.2693
Epoch~67->time:67.2963
Epoch~68->time:67.1073
Epoch~69->time:66.9198
Epoch~70->time:67.2275
Epoch~71->time:67.2434
Epoch~72->time:67.0564
Epoch~73->train_loss:0.0798, val_loss:0.3026, val_accu:0.9151, time:67.2589
Epoch~74->train_loss:0.0794, val_loss:0.3002, val_accu:0.9171, time:67.1557
Epoch~75->time:66.9851
Epoch~76->time:67.241
Epoch~77->time:67.165
Epoch~78->time:67.2755
Epoch~79->time:67.1953
Epoch~80->time:67.3552
Epoch~81->train_loss:0.0647, val_loss:0.3043, val_accu:0.9217, time:66.9627
Epoch~82->time:67.4119
Epoch~83->time:67.1
Epoch~84->time:67.4071
Epoch~85->time:67.2884
Epoch~86->time:66.801
Epoch~87->time:66.7503
Epoch~88->time:67.0908
Epoch~89->time:67.1857
Epoch~90->time:67.1215
Epoch~91->time:67.1413
Epoch~92->time:67.3045
Epoch~93->time:67.1445
Epoch~94->time:67.1247
Epoch~95->time:67.1373
Epoch~96->train_loss:0.0458, val_loss:0.2857, val_accu:0.9237, time:67.4493
Epoch~97->time:67.2091
Epoch~98->time:67.2793
Epoch~99->train_loss:0.0456, val_loss:0.2992, val_accu:0.9246, time:66.9699
Epoch~100->time:66.8566
Epoch~101->time:67.5958
Epoch~102->time:67.5006
Epoch~103->time:67.0078
Epoch~104->time:67.2188
Epoch~105->time:67.1659
Epoch~106->time:68.8034
Epoch~107->time:67.1345
Epoch~108->time:67.29
Epoch~109->time:67.2717
Epoch~110->time:67.7408
Epoch~111->time:67.8983
Epoch~112->train_loss:0.032, val_loss:0.2995, val_accu:0.9269, time:68.5537
Epoch~113->time:68.1963
Epoch~114->time:67.9205
Epoch~115->train_loss:0.0279, val_loss:0.2914, val_accu:0.9339, time:67.8875
Epoch~116->time:67.5124
Epoch~117->time:67.6174
Epoch~118->time:67.7652
Epoch~119->time:67.4414
Epoch~120->time:67.127
Epoch~121->time:66.9953
Epoch~122->time:67.2661
Epoch~123->time:67.0088
Epoch~124->time:67.0186
Epoch~125->time:66.5916
Epoch~126->time:67.4064
Epoch~127->time:67.391
Epoch~128->time:67.5799
Epoch~129->time:66.8232
Epoch~130->train_loss:0.0103, val_loss:0.2827, val_accu:0.9374, time:66.8685
Epoch~131->time:67.4236
Epoch~132->time:67.4127
Epoch~133->time:67.5287
Epoch~134->time:67.5586
Epoch~135->time:67.5791
Epoch~136->time:67.8062
Epoch~137->time:67.5485
Epoch~138->time:67.7204
Epoch~139->train_loss:0.0067, val_loss:0.2719, val_accu:0.9389, time:67.5726
Epoch~140->time:67.8099
Epoch~141->time:67.7673
Epoch~142->train_loss:0.0063, val_loss:0.2805, val_accu:0.9392, time:68.0258
Epoch~143->train_loss:0.0038, val_loss:0.27, val_accu:0.9413, time:67.5023
Epoch~144->time:67.6574
Epoch~145->train_loss:0.0037, val_loss:0.2643, val_accu:0.9414, time:67.103
Epoch~146->time:67.0306
Epoch~147->train_loss:0.0016, val_loss:0.2635, val_accu:0.9439, time:67.3876
Epoch~148->train_loss:0.0024, val_loss:0.2594, val_accu:0.9443, time:67.4642
Epoch~149->time:67.2435
Epoch~150->time:67.2693
Epoch~151->time:67.0795
Epoch~152->train_loss:0.002, val_loss:0.2713, val_accu:0.9446, time:67.6058
Epoch~153->time:67.9996
Epoch~154->train_loss:0.0011, val_loss:0.2619, val_accu:0.9451, time:67.5127
Epoch~155->time:67.7884
Epoch~156->time:67.8157
Epoch~157->train_loss:0.0008, val_loss:0.2516, val_accu:0.9458, time:67.8287
Epoch~158->time:67.4441
Epoch~159->train_loss:0.001, val_loss:0.2558, val_accu:0.9463, time:67.5672
Epoch~160->train_loss:0.0008, val_loss:0.2516, val_accu:0.9464, time:67.7877
Epoch~161->train_loss:0.0006, val_loss:0.2485, val_accu:0.9468, time:67.6893
Epoch~162->train_loss:0.0008, val_loss:0.2493, val_accu:0.9477, time:67.6096
Epoch~163->train_loss:0.0006, val_loss:0.2495, val_accu:0.9478, time:68.0043
Epoch~164->time:67.9436
Epoch~165->train_loss:0.0006, val_loss:0.2502, val_accu:0.9486, time:67.4925
Epoch~166->time:68.0329
Epoch~167->time:67.8368
Epoch~168->time:67.4031
Epoch~169->time:67.2945
Epoch~170->time:67.812
Epoch~171->train_loss:0.0004, val_loss:0.2462, val_accu:0.9494, time:67.3457
Epoch~172->time:67.3775
Epoch~173->time:67.33
Epoch~174->time:67.4067
Epoch~175->train_loss:0.0003, val_loss:0.2435, val_accu:0.9502, time:67.1236
Epoch~176->time:67.4605
Epoch~177->time:67.563
Epoch~178->time:59.9044
Epoch~179->time:67.2895
Epoch~180->time:67.6668
Epoch~181->time:67.8252
Epoch~182->time:67.3098
Epoch~183->train_loss:0.0003, val_loss:0.2388, val_accu:0.9503, time:67.1009
Epoch~184->train_loss:0.0003, val_loss:0.2397, val_accu:0.9504, time:67.4112
Epoch~185->time:67.1636
Epoch~186->time:67.4667
Epoch~187->time:67.6373
Epoch~188->time:67.6465
Epoch~189->time:67.4775
Epoch~190->time:67.372
Epoch~191->time:67.495
Epoch~192->time:67.4785
Epoch~193->time:67.1846
Epoch~194->time:67.2664
Epoch~195->time:67.7007
Epoch~196->time:67.5999
Epoch~197->time:67.3576
Epoch~198->train_loss:0.0003, val_loss:0.2361, val_accu:0.9505, time:67.3636
Epoch~199->time:67.6258
Epoch~200->time:67.3324
softstep_bottleneck_cifar10/193_o1_cifar-10-batches-py
Files already downloaded and verified
Files already downloaded and verified
Epoch~1->train_loss:1.6286, val_loss:1.4387, val_accu:0.4797, time:65.1838
Epoch~2->train_loss:1.0013, val_loss:0.9614, val_accu:0.6666, time:65.0349
Epoch~3->train_loss:0.719, val_loss:0.6691, val_accu:0.7704, time:65.3064
Epoch~4->train_loss:0.5913, val_loss:0.595, val_accu:0.7997, time:65.1905
Epoch~5->train_loss:0.5097, val_loss:0.5367, val_accu:0.8167, time:65.0163
Epoch~6->time:65.5074
Epoch~7->time:65.4651
Epoch~8->train_loss:0.3711, val_loss:0.4694, val_accu:0.8409, time:65.4671
Epoch~9->train_loss:0.3434, val_loss:0.4131, val_accu:0.8594, time:65.8362
Epoch~10->train_loss:0.3183, val_loss:0.4115, val_accu:0.8647, time:65.9753
Epoch~11->time:66.1287
Epoch~12->train_loss:0.279, val_loss:0.3974, val_accu:0.8676, time:66.0348
Epoch~13->train_loss:0.2675, val_loss:0.4031, val_accu:0.8679, time:65.7171
Epoch~14->time:65.1484
Epoch~15->train_loss:0.2414, val_loss:0.3621, val_accu:0.8779, time:65.1311
Epoch~16->time:65.2036
Epoch~17->train_loss:0.2211, val_loss:0.342, val_accu:0.8881, time:65.3453
Epoch~18->train_loss:0.209, val_loss:0.3493, val_accu:0.889, time:65.323
Epoch~19->time:65.154
Epoch~20->time:65.1876
Epoch~21->time:65.3002
Epoch~22->time:65.25
Epoch~23->train_loss:0.1746, val_loss:0.3266, val_accu:0.897, time:64.9713
Epoch~24->time:65.1826
Epoch~25->time:65.059
Epoch~26->time:65.4021
Epoch~27->time:65.1459
Epoch~28->time:65.0167
Epoch~29->time:65.1559
Epoch~30->train_loss:0.1454, val_loss:0.3346, val_accu:0.898, time:65.3217
Epoch~31->train_loss:0.1461, val_loss:0.3165, val_accu:0.9005, time:65.253
Epoch~32->time:65.0992
Epoch~33->time:64.9983
Epoch~34->train_loss:0.1334, val_loss:0.3135, val_accu:0.9029, time:64.6808
Epoch~35->time:65.4351
Epoch~36->time:65.4811
Epoch~37->time:65.1125
Epoch~38->time:65.7621
Epoch~39->time:66.2088
Epoch~40->train_loss:0.1203, val_loss:0.3036, val_accu:0.9078, time:66.1362
Epoch~41->time:66.0923
Epoch~42->train_loss:0.107, val_loss:0.3001, val_accu:0.9133, time:65.9441
Epoch~43->time:65.3799
Epoch~44->time:65.2412
Epoch~45->time:65.1954
Epoch~46->time:65.2719
Epoch~47->time:65.1575
Epoch~48->time:64.8258
Epoch~49->time:65.3474
Epoch~50->time:65.0614
Epoch~51->time:65.0875
Epoch~52->time:65.2691
Epoch~53->time:65.1822
Epoch~54->time:65.2452
Epoch~55->time:65.2334
Epoch~56->time:65.1855
Epoch~57->time:65.0649
Epoch~58->time:65.3109
Epoch~59->time:65.1647
Epoch~60->time:65.0302
Epoch~61->time:65.0069
Epoch~62->train_loss:0.0848, val_loss:0.3035, val_accu:0.9136, time:65.1815
Epoch~63->time:64.9794
Epoch~64->time:65.2639
Epoch~65->time:65.5625
Epoch~66->time:65.0882
Epoch~67->time:65.7802
Epoch~68->time:66.0523
Epoch~69->time:65.8249
Epoch~70->time:66.0431
Epoch~71->time:65.7391
Epoch~72->time:65.1028
Epoch~73->time:65.0111
Epoch~74->time:64.8274
Epoch~75->time:65.2909
Epoch~76->time:64.9951
Epoch~77->time:65.0123
Epoch~78->train_loss:0.0699, val_loss:0.3011, val_accu:0.9188, time:65.0703
Epoch~79->time:65.1578
Epoch~80->time:65.0252
Epoch~81->train_loss:0.0634, val_loss:0.2962, val_accu:0.9205, time:65.0358
Epoch~82->time:64.7406
Epoch~83->time:64.9158
Epoch~84->time:65.1127
Epoch~85->time:65.1096
Epoch~86->time:65.1276
Epoch~87->time:65.2942
Epoch~88->time:65.0229
Epoch~89->time:65.2151
Epoch~90->time:65.1234
Epoch~91->time:64.9241
Epoch~92->time:65.5105
Epoch~93->time:65.2153
Epoch~94->time:65.215
Epoch~95->time:65.4502
Epoch~96->time:65.9964
Epoch~97->train_loss:0.0406, val_loss:0.3098, val_accu:0.923, time:65.8835
Epoch~98->time:65.9101
Epoch~99->time:65.374
Epoch~100->time:65.0078
Epoch~101->time:65.1382
Epoch~102->train_loss:0.0381, val_loss:0.2857, val_accu:0.9268, time:65.0942
Epoch~103->time:65.0261
Epoch~104->time:65.104
Epoch~105->time:65.1148
Epoch~106->time:65.0958
Epoch~107->time:65.0611
Epoch~108->time:64.9521
Epoch~109->time:65.0142
Epoch~110->time:65.1495
Epoch~111->time:65.1227
Epoch~112->time:64.9322
Epoch~113->time:65.0071
Epoch~114->train_loss:0.022, val_loss:0.3161, val_accu:0.9271, time:64.7509
Epoch~115->time:64.7793
Epoch~116->time:64.798
Epoch~117->time:64.8576
Epoch~118->time:65.0187
Epoch~119->time:65.3289
Epoch~120->time:65.202
Epoch~121->train_loss:0.0216, val_loss:0.3057, val_accu:0.9294, time:65.0513
Epoch~122->time:65.5787
Epoch~123->train_loss:0.0191, val_loss:0.3084, val_accu:0.93, time:65.9769
Epoch~124->time:65.8781
Epoch~125->train_loss:0.015, val_loss:0.3087, val_accu:0.9308, time:65.8667
Epoch~126->time:65.4455
Epoch~127->time:64.9655
Epoch~128->time:65.0805
Epoch~129->train_loss:0.0099, val_loss:0.3104, val_accu:0.9342, time:65.1343
Epoch~130->time:65.1247
Epoch~131->time:64.6978
Epoch~132->time:64.9927
Epoch~133->time:64.7591
Epoch~134->time:64.979
Epoch~135->time:65.0204
Epoch~136->train_loss:0.008, val_loss:0.3069, val_accu:0.9348, time:65.1552
Epoch~137->time:65.0709
Epoch~138->time:64.9945
